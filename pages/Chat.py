import streamlit as st
import pandas as pd
import unicodedata
import re
import html
import os
import sys
import openai
import time
from dotenv import load_dotenv
from datetime import datetime
from pathlib import Path

from langchain.docstore.document import Document
from langchain.chat_models import ChatOpenAI
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.prompts import PromptTemplate
from langchain.schema import SystemMessage, HumanMessage, AIMessage

# è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆHomeãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆã™ã‚‹ãŸã‚ï¼‰
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import auth

# Home.pyã‹ã‚‰å…±é€šé–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from Home import display_quote, load_highlights, normalize_japanese_text, load_user_highlights

# ç’°å¢ƒå¤‰æ•°ã®ãƒ­ãƒ¼ãƒ‰
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ | Booklight AI", 
    page_icon="ğŸ’¬",
    layout="centered",
    initial_sidebar_state="expanded"
)

# CSSãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def local_css(file_name):
    with open(file_name) as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

# ãƒãƒ£ãƒƒãƒˆç”¨ã‚«ã‚¹ã‚¿ãƒ CSS
def add_chat_css():
    st.markdown("""
    <style>
    /* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å…¨ä½“ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .chat-message {
        padding: 1rem;
        border-radius: 0.8rem;
        margin-bottom: 1rem;
        display: flex;
        flex-direction: column;
    }

    /* ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .user-message {
        background-color: #2a75bb;
        border-top-right-radius: 0.2rem;
        align-self: flex-end;
        color: white;
    }

    /* AIãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .ai-message {
        background-color: #383838;
        border-top-left-radius: 0.2rem;
        align-self: flex-start;
    }

    /* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒŠ */
    .message-container {
        display: flex;
        flex-direction: column;
        max-width: 90%;
    }

    /* ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ†ã‚­ã‚¹ãƒˆ */
    .message-text {
        color: inherit;
        padding: 0;
        margin: 0;
    }

    /* å¼•ç”¨æƒ…å ± */
    .source-info {
        margin-top: 0.8rem;
        padding-top: 0.8rem;
        border-top: 1px solid rgba(255, 255, 255, 0.2);
        font-size: 0.85rem;
        color: rgba(255, 255, 255, 0.7);
    }

    /* å¼•ç”¨ãƒªã‚¹ãƒˆ */
    .sources-list {
        margin-top: 0.5rem;
        padding-left: 1rem;
    }

    /* å…¥åŠ›ã‚¨ãƒªã‚¢ */
    .input-area {
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        padding: 1rem;
        background-color: #1E1E1E;
        border-top: 1px solid #333;
        display: flex;
        gap: 0.5rem;
    }
    
    /* ãƒãƒ£ãƒƒãƒˆã‚³ãƒ³ãƒ†ãƒŠã«ä¸‹éƒ¨ä½™ç™½ã‚’è¿½åŠ  */
    .chat-container {
        margin-bottom: 5rem;
    }
    
    /* ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®é«˜ã•è‡ªå‹•èª¿æ•´ */
    .stTextArea textarea {
        min-height: 100px !important;
    }
    
    /* å¼•ç”¨ã‚«ãƒ¼ãƒ‰ã‚’ãƒãƒ£ãƒƒãƒˆå†…ã«åŸ‹ã‚è¾¼ã¿ */
    .chat-message .quote-container {
        margin: 0.5rem 0;
        background-color: rgba(255, 255, 255, 0.1);
    }
    
    /* ãƒãƒ£ãƒƒãƒˆå†…ã®å¼•ç”¨ãƒ†ã‚­ã‚¹ãƒˆ */
    .chat-message .quote-text {
        color: rgba(255, 255, 255, 0.9);
    }
    </style>
    """, unsafe_allow_html=True)

# é€šå¸¸ã®CSSã‚‚èª­ã¿è¾¼ã¿
local_css("style.css")
# ãƒãƒ£ãƒƒãƒˆç”¨ã®CSSã‚’è¿½åŠ 
add_chat_css()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.image("images/booklight_ai_banner.png", use_container_width=True)
st.sidebar.title("Booklight AI")
st.sidebar.markdown("ğŸ“š ã‚ãªãŸã®èª­æ›¸ã‚’AIãŒç…§ã‚‰ã™")
st.sidebar.markdown("---")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ­ã‚°ã‚¤ãƒ³/ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
if auth.is_user_authenticated():
    user_info = st.session_state.user_info
    st.sidebar.markdown(f"### ã‚ˆã†ã“ãã€{user_info.get('name', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼')}ã•ã‚“ï¼")
    st.sidebar.markdown(f"ğŸ“§ {user_info.get('email', '')}")
    
    if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
        auth.logout()
        st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰
else:
    st.sidebar.markdown("### ãƒ­ã‚°ã‚¤ãƒ³")
    auth_url = auth.get_google_auth_url()
    if auth_url:
        st.sidebar.markdown(f"[Googleã§ãƒ­ã‚°ã‚¤ãƒ³]({auth_url})")
    else:
        st.sidebar.error("èªè¨¼è¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
st.sidebar.markdown("---")
st.sidebar.markdown("### ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
st.sidebar.markdown("[ğŸ  ãƒ›ãƒ¼ãƒ ](Home.py)")
st.sidebar.markdown("[ğŸ” æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰](pages/Search.py)")
st.sidebar.markdown("[ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰](pages/Chat.py)")
st.sidebar.markdown("[ğŸ“š æ›¸ç±ä¸€è¦§](pages/BookList.py)")
st.sidebar.markdown("[ğŸ“¤ ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰](pages/Upload.py)")

# èªè¨¼ãƒ•ãƒ­ãƒ¼ã®å‡¦ç†
auth_success = auth.handle_auth_flow()
if auth_success:
    st.success("ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸï¼")
    st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ä¼šè©±ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³ã‚’é…ç½®
st.sidebar.markdown("### ãƒãƒ£ãƒƒãƒˆè¨­å®š")
if st.sidebar.button("ä¼šè©±ã‚’ãƒªã‚»ãƒƒãƒˆ"):
    for key in list(st.session_state.keys()):
        if key.startswith("chat_"):
            del st.session_state[key]
    st.rerun()

# æ–°è¦ä¼šè©±ãƒœã‚¿ãƒ³
if st.sidebar.button("æ–°è¦ä¼šè©±ã‚’é–‹å§‹"):
    # ç¾åœ¨ã®ä¼šè©±IDã‚’ä¿å­˜
    if "chat_history" in st.session_state:
        if "saved_chats" not in st.session_state:
            st.session_state.saved_chats = []
        # ä¼šè©±ã«åå‰ã‚’ã¤ã‘ã‚‹ï¼ˆæœ€åˆã®è³ªå•ã‚’ä½¿ç”¨ï¼‰
        if st.session_state.chat_history:
            first_question = st.session_state.chat_history[0]["content"]
            chat_name = first_question[:30] + "..." if len(first_question) > 30 else first_question
            st.session_state.saved_chats.append({
                "name": chat_name,
                "history": st.session_state.chat_history,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M")
            })
    
    # ä¼šè©±å±¥æ­´ã‚’ãƒªã‚»ãƒƒãƒˆ
    for key in list(st.session_state.keys()):
        if key.startswith("chat_"):
            del st.session_state[key]
    st.rerun()

# ä¿å­˜ã•ã‚ŒãŸä¼šè©±ä¸€è¦§ï¼ˆã‚ã‚Œã°è¡¨ç¤ºï¼‰
if "saved_chats" in st.session_state and st.session_state.saved_chats:
    st.sidebar.markdown("### éå»ã®ä¼šè©±")
    for i, chat in enumerate(st.session_state.saved_chats):
        chat_btn = st.sidebar.button(f"{chat['name']} ({chat['timestamp']})", key=f"saved_chat_{i}")
        if chat_btn:
            st.session_state.chat_history = chat["history"]
            st.rerun()

# -------------------------------------------
# ãƒã‚¤ãƒ©ã‚¤ãƒˆVectorStore
# -------------------------------------------
@st.cache_resource
def get_highlight_vectorstore():
    # OpenAI Embeddings
    embeddings_model = OpenAIEmbeddings(
        model="text-embedding-3-small"
    )
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã‹ã©ã†ã‹
    if auth.is_user_authenticated():
        user_id = auth.get_current_user_id()
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’èª­ã¿è¾¼ã¿
        highlight_docs = load_user_highlights(user_id)
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä½œæˆ
        persist_dir = f"./csv_chroma_db/highlights_user_{user_id}"
        st.info(f"{st.session_state.user_info.get('name', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼')}ã•ã‚“ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒãƒ£ãƒƒãƒˆã—ã¾ã™ã€‚")
    else:
        # å…±é€šã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’èª­ã¿è¾¼ã¿
        highlight_docs = load_highlights()
        persist_dir = "./csv_chroma_db/highlights_v2"
    
    return Chroma.from_documents(
        documents=highlight_docs,
        embedding=embeddings_model,
        persist_directory=persist_dir
    )

# æ³¨æ„: ã“ã®é–¢æ•°ã¯å†…éƒ¨ã§highlight_docsã‚’ç”Ÿæˆã™ã‚‹ãŸã‚ã€
# å¼•æ•°ã¨ã—ã¦æ¸¡ã™å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“
highlight_vs = get_highlight_vectorstore()

# -------------------------------------------
# ãƒãƒ£ãƒƒãƒˆã®è¡¨ç¤º
# -------------------------------------------
def display_chat_message(message, is_user=False):
    if is_user:
        st.markdown(f"""
        <div class="chat-message user-message">
            <div class="message-container">
                <p class="message-text">{message}</p>
            </div>
        </div>
        """, unsafe_allow_html=True)
    else:
        # AIå¿œç­”ã®HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—
        safe_message = html.escape(message["content"])
        
        # å¼•ç”¨è¡¨ç¤ºï¼ˆã‚‚ã—ã‚ã‚Œã°ï¼‰
        sources_html = ""
        if "source_documents" in message:
            sources = message["source_documents"]
            if sources:
                sources_html = """<div class="source-info">å‚ç…§ã—ãŸæ›¸ç±:</div>
                <div class="sources-list">"""
                
                seen_titles = set()
                for doc in sources[:5]:  # è¡¨ç¤ºã™ã‚‹å¼•ç”¨ã¯æœ€å¤§5ã¤ã¾ã§
                    title = doc.metadata.get("original_title", doc.metadata.get("title", "ä¸æ˜"))
                    # é‡è¤‡æ’é™¤
                    if title in seen_titles:
                        continue
                    seen_titles.add(title)
                    sources_html += f"<div>ğŸ“š {html.escape(title)}</div>"
                
                sources_html += "</div>"
        
        st.markdown(f"""
        <div class="chat-message ai-message">
            <div class="message-container">
                <p class="message-text">{safe_message}</p>
                {sources_html}
            </div>
        </div>
        """, unsafe_allow_html=True)

# -------------------------------------------
# è­°è«–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ (æ”¹å–„ç‰ˆ)
# -------------------------------------------
discussion_prompt_template = """
ã‚ãªãŸã¯æ›¸ç±ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ã‚’å‚ç…§ã§ãã‚‹æ–‡å­¦ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ä¼šè©±ã‚’é€šã˜ã¦ã€èª­æ›¸ä½“é¨“ã‚„çŸ¥è­˜ã®æ·±åŒ–ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚

ä»¥ä¸‹ã®æ›¸ç±ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚
ã‚‚ã—ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ãŒè³ªå•ã«ç›´æ¥é–¢é€£ã—ã¦ã„ãªã„å ´åˆã¯ã€ã‚ãªãŸè‡ªèº«ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚

ä¼šè©±ã®å±¥æ­´:
{chat_history}

æ›¸ç±ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±:
{summaries}

ã€è³ªå•ã€‘
{question}

å›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚æ›¸ç±ã®å¼•ç”¨ã‚’ä½¿ç”¨ã—ãŸå ´åˆã¯ã€ãã®äº‹å®Ÿã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
ãŸã ã—ã€å›ç­”ã¯è‡ªç„¶ãªä¼šè©±ã®æµã‚Œã‚’ä¿ã¡ã€å­¦è¡“çš„ã™ãã‚‹å°è±¡ã‚’ä¸ãˆãªã„ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚
"""

DISCUSSION_PROMPT = PromptTemplate(
    template=discussion_prompt_template,
    input_variables=["summaries", "question", "chat_history"]
)

# -------------------------------------------
# ãƒãƒ£ãƒƒãƒˆå‡¦ç†é–¢æ•°
# -------------------------------------------
def process_chat(user_input):
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
    # å…¥åŠ›ãŒç©ºãªã‚‰å‡¦ç†ã—ãªã„
    if not user_input.strip():
        return
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ 
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    
    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’LangChainå½¢å¼ã«å¤‰æ›
    langchain_history = ""
    for msg in st.session_state.chat_history[:-1]:  # æœ€å¾Œã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’é™¤ã
        role_prefix = "ãƒ¦ãƒ¼ã‚¶ãƒ¼: " if msg["role"] == "user" else "ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ: "
        langchain_history += f"{role_prefix}{msg['content']}\n\n"
    
    # å›ç­”ç”Ÿæˆã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
        # LLMæº–å‚™
        llm = ChatOpenAI(model="gpt-4-turbo", temperature=0.2)
        
        # é–¢é€£ã™ã‚‹ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’æ¤œç´¢
        search_results = highlight_vs.similarity_search(user_input, k=8)
        
        # ãƒã‚¤ãƒ©ã‚¤ãƒˆæƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
        highlights_text = ""
        for i, doc in enumerate(search_results, 1):
            title = doc.metadata.get("original_title", "ä¸æ˜ãªæ›¸ç±")
            author = doc.metadata.get("original_author", "")
            content = doc.metadata.get("original_content", doc.page_content)
            highlights_text += f"[{i}] ã€Œ{content}ã€ï¼ˆ{title}, {author}ï¼‰\n\n"
        
        # å›ç­”ã‚’ç”Ÿæˆ
        messages = [
            SystemMessage(content="ã‚ãªãŸã¯æ›¸ç±ã®çŸ¥è­˜ã‚’ã‚‚ã¨ã«ä¼šè©±ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"),
            HumanMessage(content=DISCUSSION_PROMPT.format(
                summaries=highlights_text,
                question=user_input,
                chat_history=langchain_history
            ))
        ]
        
        response = llm(messages)
        
        # AIå¿œç­”ã‚’å±¥æ­´ã«è¿½åŠ 
        ai_response = {
            "role": "assistant", 
            "content": response.content,
            "source_documents": search_results
        }
        st.session_state.chat_history.append(ai_response)
        
        # å¼•ç”¨ã—ãŸç‰¹å®šã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’è¡¨ç¤º
        if search_results:
            st.session_state.last_citations = search_results

# -------------------------------------------
# ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
# -------------------------------------------
st.title("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰")
st.write("æ›¸ç±ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’ã‚‚ã¨ã«ãƒãƒ£ãƒƒãƒˆã§ä¼šè©±ã—ã¾ã—ã‚‡ã†ã€‚è³ªå•ã‚„è­°è«–ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

if "chat_history" in st.session_state:
    for message in st.session_state.chat_history:
        if message["role"] == "user":
            display_chat_message(message["content"], is_user=True)
        else:
            display_chat_message(message)

st.markdown('</div>', unsafe_allow_html=True)

# é€ä¿¡ãƒœã‚¿ãƒ³ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
def on_submit():
    if st.session_state.user_input.strip():
        # å…¥åŠ›å†…å®¹ã‚’ã‚³ãƒ”ãƒ¼
        current_input = st.session_state.user_input
        # ãƒãƒ£ãƒƒãƒˆå‡¦ç†å®Ÿè¡Œ
        process_chat(current_input)
        # å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ãƒ•ãƒ©ã‚°ã‚’è¨­å®š
        st.session_state.clear_input = True
        # ç”»é¢ã‚’æ›´æ–°ã—ã¦çµæœã‚’è¡¨ç¤º
        st.rerun()

# å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ã®åˆæœŸåŒ–
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# ã‚¯ãƒªã‚¢ãƒ•ãƒ©ã‚°ã®åˆæœŸåŒ–
if "clear_input" in st.session_state and st.session_state.clear_input:
    st.session_state.user_input = ""
    st.session_state.clear_input = False

# ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ ï¼ˆä¸‹éƒ¨å›ºå®šï¼‰
with st.container():
    st.markdown('<div style="height: 5rem;"></div>', unsafe_allow_html=True)  # ã‚¹ãƒšãƒ¼ã‚¹ç¢ºä¿
    
    # å…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    col1, col2 = st.columns([5, 1])
    
    with col1:
        user_input = st.text_area(
            "è³ªå•ã‚„è­°è«–ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›",
            height=100,
            key="user_input",
            label_visibility="collapsed",
            placeholder="è³ªå•ã‚„è­°è«–ã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯ã‚’å…¥åŠ›..."
        )
    
    with col2:
        st.markdown('<div style="height: 0.5rem;"></div>', unsafe_allow_html=True)  # ä½ç½®èª¿æ•´
        submit = st.button("é€ä¿¡", on_click=on_submit, use_container_width=True)
    
    # Enterã‚­ãƒ¼ã§ã®é€ä¿¡å‡¦ç†
    if user_input and user_input.endswith("\n"):
        on_submit()

# å¼•ç”¨ã®è©³ç´°è¡¨ç¤ºï¼ˆæŠ˜ã‚ŠãŸãŸã¿ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼‰
if "last_citations" in st.session_state and st.session_state.last_citations:
    with st.expander("å‚ç…§ã—ãŸæ›¸ç±ãƒã‚¤ãƒ©ã‚¤ãƒˆ", expanded=False):
        st.write("ç›´è¿‘ã®è³ªå•ã«å¯¾ã—ã¦å‚ç…§ã—ãŸãƒã‚¤ãƒ©ã‚¤ãƒˆ:")
        
        for i, doc in enumerate(st.session_state.last_citations, start=1):
            # ã‚ªãƒªã‚¸ãƒŠãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å„ªå…ˆçš„ã«ä½¿ç”¨
            title = doc.metadata.get("original_title", doc.metadata.get("title", "ä¸æ˜"))
            author = doc.metadata.get("original_author", doc.metadata.get("author", ""))
            content = doc.metadata.get("original_content", doc.page_content)
            
        # å¼•ç”¨è¡¨ç¤ºé–¢æ•°ã‚’ä½¿ç”¨ (ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚­ãƒ¼ã‚’ç”Ÿæˆ)
        display_quote(content, title, author, f"chat_citation_{i}")

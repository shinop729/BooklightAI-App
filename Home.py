import streamlit as st
import pandas as pd
import os
import urllib.parse
import unicodedata
import re
import random
from langchain.schema import Document
from dotenv import load_dotenv
import openai
import urllib.parse
from pathlib import Path
import auth

def local_css(file_name):
    """Load and inject a local CSS file into the Streamlit app"""
    with open(file_name) as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

# ã‚¢ãƒ—ãƒªå…¨ä½“ã®è¨­å®š
def setup_app():
    load_dotenv()
    openai.api_key = os.getenv("OPENAI_API_KEY")
    
    st.set_page_config(page_title="Booklight AI", layout="wide")
    
    # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’è¡¨ç¤º
    st.write("ç’°å¢ƒå¤‰æ•°ã®ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
    st.write(f"GOOGLE_CLIENT_ID: {os.getenv('GOOGLE_CLIENT_ID')}")
    st.write(f"GOOGLE_CLIENT_SECRET: {os.getenv('GOOGLE_CLIENT_SECRET')}")
    st.write(f"REDIRECT_URI: {os.getenv('REDIRECT_URI')}")
    
    st.sidebar.image("images/booklight_ai_banner.png", use_container_width=True)
    st.sidebar.title("Booklight AI")
    st.sidebar.markdown("ğŸ“š ã‚ãªãŸã®èª­æ›¸ã‚’AIãŒç…§ã‚‰ã™")
    st.sidebar.markdown("---")

import urllib.parse
import unicodedata
import re
import pandas as pd
import random
import os
import openai
from langchain_core.documents import Document

def normalize_japanese_text(text: str) -> str:
    import unicodedata
    import re
    text = unicodedata.normalize('NFKC', text)
    text = text.lower()
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def load_highlights():
    df = pd.read_csv("docs/KindleHighlights.csv")
    docs = []
    for _, row in df.iterrows():
        normalized_highlight = normalize_japanese_text(row["ãƒã‚¤ãƒ©ã‚¤ãƒˆå†…å®¹"])
        doc = Document(
            page_content=normalized_highlight,
            metadata={
                "original_title": row["æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«"],
                "original_author": row["è‘—è€…"]
            }
        )
        docs.append(doc)
    return docs

@st.cache_resource
def load_book_info(user_id=None):
    """æ›¸ç±æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ä½¿ç”¨ï¼‰"""
    if user_id:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        user_highlights_path = auth.USER_DATA_DIR / "docs" / user_id / "KindleHighlights.csv"
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨
        if user_highlights_path.exists():
            df = pd.read_csv(user_highlights_path)
        else:
            # å­˜åœ¨ã—ãªã„å ´åˆã¯å…±é€šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
            df = pd.read_csv("docs/KindleHighlights.csv")
    else:
        # ãƒ­ã‚°ã‚¤ãƒ³ã—ã¦ã„ãªã„å ´åˆã¯å…±é€šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        df = pd.read_csv("docs/KindleHighlights.csv")
    
    df = df[df["æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«"] != ""]
    
    # Group by book title and aggregate highlights
    grouped = df.groupby("æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«")["ãƒã‚¤ãƒ©ã‚¤ãƒˆå†…å®¹"].agg(lambda x: "\n".join(x)).reset_index()
    
    book_info = {}
    for _, row in grouped.iterrows():
        title = row["æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«"]
        # Get author for this book (taking the first one if multiple)
        author = df[df["æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«"] == title]["è‘—è€…"].iloc[0] if not df[df["æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«"] == title]["è‘—è€…"].empty else ""
        
        # Create a dictionary with the required structure for Search.py
        book_info[title] = {
            "title_text": title,
            "normalized_title": normalize_japanese_text(title),
            "normalized_summary": normalize_japanese_text(row["ãƒã‚¤ãƒ©ã‚¤ãƒˆå†…å®¹"]),
            "author": author
        }
    return book_info

def display_quote(content, title, author, index=0):
    """
    Home.pyç”¨ã®å¼•ç”¨è¡¨ç¤ºé–¢æ•° - æ›¸ç±è©³ç´°ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ä»˜ã
    """
    # ãƒ›ãƒ¼ãƒ ãƒšãƒ¼ã‚¸ç”¨ã®ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆãƒ€ãƒ¼ã‚¯ãƒ¢ãƒ¼ãƒ‰å¯¾å¿œï¼‰
    quote_html = f"""
    <div style="padding:15px; border-radius:8px; background-color:#2a2a2a; margin-bottom:15px; box-shadow: 0 2px 5px rgba(0,0,0,0.2);">
        <p style="color:#ffffff; font-size:16px; line-height:1.6; margin-bottom:12px;">{content}</p>
        <div style="text-align:right;">
            <span style="color:#4da6ff; font-weight:500;">{title} / {author}</span>
        </div>
    </div>
    """
    st.markdown(quote_html, unsafe_allow_html=True)
    
    # è©³ç´°ãƒšãƒ¼ã‚¸ã¸ã®ãƒªãƒ³ã‚¯ã‚’è¿½åŠ 
    col1, col2 = st.columns([3, 1])
    with col2:
        if st.button(f"è©³ç´°ã‚’è¦‹ã‚‹", key=f"home_detail_{index}"):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä¿å­˜
            st.session_state.selected_book_title = title
            # BookDetailãƒšãƒ¼ã‚¸ã«ãƒªãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆ
            st.switch_page("pages/BookDetail.py")

def load_user_highlights(user_id):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    user_highlights_path = auth.USER_DATA_DIR / "docs" / user_id / "KindleHighlights.csv"
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯å…±é€šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    if not user_highlights_path.exists():
        return load_highlights()
    
    df = pd.read_csv(user_highlights_path)
    docs = []
    for _, row in df.iterrows():
        normalized_highlight = normalize_japanese_text(row["ãƒã‚¤ãƒ©ã‚¤ãƒˆå†…å®¹"])
        doc = Document(
            page_content=normalized_highlight,
            metadata={
                "original_title": row["æ›¸ç±ã‚¿ã‚¤ãƒˆãƒ«"],
                "original_author": row["è‘—è€…"]
            }
        )
        docs.append(doc)
    return docs

def main():
    setup_app()
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    auth.create_user_directories()
    
    # èªè¨¼ãƒ•ãƒ­ãƒ¼ã®å‡¦ç†
    auth_success = auth.handle_auth_flow()
    if auth_success:
        st.success("ãƒ­ã‚°ã‚¤ãƒ³ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ­ã‚°ã‚¤ãƒ³/ãƒ­ã‚°ã‚¢ã‚¦ãƒˆãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
    st.sidebar.markdown("---")
    if auth.is_user_authenticated():
        user_info = st.session_state.user_info
        st.sidebar.markdown(f"### ã‚ˆã†ã“ãã€{user_info.get('name', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼')}ã•ã‚“ï¼")
        st.sidebar.markdown(f"ğŸ“§ {user_info.get('email', '')}")
        
        if st.sidebar.button("ãƒ­ã‚°ã‚¢ã‚¦ãƒˆ"):
            auth.logout()
            st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ­ãƒ¼ãƒ‰
    else:
        st.sidebar.markdown("### ãƒ­ã‚°ã‚¤ãƒ³")
        st.sidebar.write("ãƒ­ã‚°ã‚¤ãƒ³ãƒ‡ãƒãƒƒã‚°æƒ…å ±:")
        auth_url = auth.get_google_auth_url()
        st.sidebar.write(f"auth_url: {auth_url}")
        if auth_url:
            st.sidebar.markdown(f"[Googleã§ãƒ­ã‚°ã‚¤ãƒ³]({auth_url})")
            # ç›´æ¥ãƒªãƒ³ã‚¯ã‚‚è¡¨ç¤º
            st.sidebar.write("ç›´æ¥ãƒªãƒ³ã‚¯:")
            st.sidebar.write(auth_url)
        else:
            st.sidebar.error("èªè¨¼è¨­å®šãŒä¸å®Œå…¨ã§ã™ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("[ğŸ” æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰](pages/Search.py)")
    st.sidebar.markdown("[ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰](pages/Chat.py)")
    st.sidebar.markdown("[ğŸ“š æ›¸ç±ä¸€è¦§](pages/BookList.py)")
    st.sidebar.markdown("[ğŸ“¤ ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰](pages/Upload.py)")
    
    # ãƒã‚¤ãƒ©ã‚¤ãƒˆã®èª­ã¿è¾¼ã¿ï¼ˆãƒ­ã‚°ã‚¤ãƒ³ä¸­ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼å›ºæœ‰ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
    if auth.is_user_authenticated():
        user_id = auth.get_current_user_id()
        highlight_docs = load_user_highlights(user_id)
        st.title(f"{st.session_state.user_info.get('name', 'ãƒ¦ãƒ¼ã‚¶ãƒ¼')}ã•ã‚“ã®Booklight AI")
    else:
        highlight_docs = load_highlights()
        st.title("Booklight AI")
    
    # ãƒ­ã‚°ã‚¤ãƒ³çŠ¶æ…‹ã«å¿œã˜ãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º
    if auth.is_user_authenticated():
        st.info("ãƒ­ã‚°ã‚¤ãƒ³ä¸­ã§ã™ã€‚ã‚ãªãŸå°‚ç”¨ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")
    else:
        st.info("ãƒ­ã‚°ã‚¤ãƒ³ã™ã‚‹ã¨ã€ã‚ãªãŸå°‚ç”¨ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã§ãã¾ã™ã€‚")

    if not highlight_docs:
        st.write("ãƒã‚¤ãƒ©ã‚¤ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
    else:
        random_docs = random.sample(highlight_docs, min(3, len(highlight_docs)))
        for i, doc in enumerate(random_docs):
            title = doc.metadata.get("original_title", "ä¸æ˜ãªã‚¿ã‚¤ãƒˆãƒ«")
            author = doc.metadata.get("original_author", "ä¸æ˜ãªè‘—è€…")
            content = doc.page_content[:300] + "..." if len(doc.page_content) > 300 else doc.page_content
            display_quote(content, title, author, i)

if __name__ == "__main__":
    main()
